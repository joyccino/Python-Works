{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "유방암판별모델도전_Moon",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJZv12oWHSvH"
      },
      "source": [
        "# KNN(k-nearest neighbors algorithm) 을 사용하여<br>\n",
        "# 악성 유방암을 판별하는 모델을 생성하는 예제를 푸는데 도전해 보도록 하겠습니다.\n",
        "\n",
        "- 패턴 인식에서, k-최근접 이웃 알고리즘(또는 줄여서 k-NN)은 분류나 회귀에 사용되는 비모수 방식이라고 합니다.<br> 두 경우 모두 입력이 특징 공간 내 k개의 가장 가까운 훈련 데이터로 구성되어 있다고 합니다. (wikipedia) <br>\n",
        "- 지도학습 중에 분류 문제에 사용하는 알고리즘입니다. <br>\n",
        "분류 문제란 새로운 데이터가 들어왔을 때 기존 데이터의 그룹 중 어떤 그룹에 속하는지를 분류하는 문제를 말합니다. <br>\n",
        "- 데이터는 사이킷 런과 위스콘신 대학교에서 제공하는 유방암 데이터셋을 사용합니다.\n",
        "- 두 가지 방법을 사용해 보았는데: 첫번째는 정규화를 거치지 않은 심플한 방법, 두번째는 정규화 작업을 추가한 방식입니다. <br>\n",
        "두번째 예제 풀이를 참고한 곳: (http://hleecaster.com/ml-knn-classifier-example/) 설명이 잘 되어있어 이해가 쉬웠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joAHzxQsGCIf"
      },
      "source": [
        "# KNN 을 사용한 예제 풀이 후 Decision Tree 와 Perceptron 도 사용해 실험해 보겠습니다.\n",
        "(7 Oct 2020) 예습을 위해 유방암 데이터를 이용해서 위의 두가지 분류기를 사용해 학습시켜 보기로 합니다. <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udyEt7VxGRJf"
      },
      "source": [
        "\n",
        "#1 데이터 import 및 형태 확인하기 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93A_EM4-GF9q",
        "outputId": "536ce7e8-ac22-4e45-a05c-588475526eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "source": [
        "# coding: utf-8\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "print(\"cancer.keys : \\n{}\".format(cancer.keys()))\n",
        "# cancer.keys : \n",
        "# dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n",
        "\n",
        "\n",
        "print(\"유방암 데이터의 형태 : {}\".format(cancer.data.shape))\n",
        "# 유방암 데이터의 형태 : (569, 30)\n",
        "# 569개 데이터 포인트(표본)를 가지고 있음. 특성은 30개\n",
        "\n",
        "print(\"클래스 별 샘플 개수 : \\n {}\".format({n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))}))\n",
        "# 클래스 별 샘플 개수 : \n",
        "#  {'malignant': 212, 'benign': 357}\n",
        "# 569개 데이터 포인트 중 212개는 악성, 357개는 양성입니다.\n",
        "\n",
        "print(\"특성 이름 : {}\\n\".format(cancer.feature_names))\n",
        "# 특성 이름 : ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
        "#  'mean smoothness' 'mean compactness' 'mean concavity'......\n",
        "#  'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
        "\n",
        "# 데이터에 관한 자세한 정보는 cancer.DESCR에서 확인할 수 있습니다. 각각 특성에 대한 번역은 스킵하겠습니다.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cancer.keys : \n",
            "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
            "유방암 데이터의 형태 : (569, 30)\n",
            "클래스 별 샘플 개수 : \n",
            " {'malignant': 212, 'benign': 357}\n",
            "특성 이름 : ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8gVps3gG636"
      },
      "source": [
        "#2 최근접 이웃 알고리즘(KNN) 구현하기\n",
        "- train/test 세트를 8:2 비율로 나누어 학습한 후 <br>\n",
        "이웃의 수에 따른 정확도를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "936Z7Q89GjWc",
        "outputId": "e3095965-b157-488f-c263-d897592472e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        " # coding: utf-8\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#import mglearn <<< 이거.. 코랩에 설치가 안되어있는지 에러가 나서 찾아보니\n",
        "#                   한 머신러닝 교과서 작가분께서 직접 만드신 라이브러리라고 합니다.\n",
        "#                   제외해도 별다른 문제가 없는것 같길래 일단은 주석처리 하겠습니당.\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# 훈련/테스트 세트로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data,cancer.target,stratify=cancer.target, random_state=66)\n",
        "\n",
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "# 1~10까지 이웃의 개수를 적용\n",
        "neighbors_settings = range(1,11)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier #KNN을 위한 사이킷런의 머신러닝 라이브러리입니다.\n",
        "for n_neighbors in neighbors_settings:\n",
        "    # fit() 메서드는 self 객체를 반환합니다.\n",
        "    # 객체 생성과 fit 메서드를 한줄에 쓸 수 있다고 합니다.\n",
        "    # fit()을 사용하여 주어진 데이터에 우리가 원하는 함수 꼴로 Model을 fitting합니다.\n",
        "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    clf.fit(X_train, y_train)\n",
        "    # 훈련 세트 정확도 저장\n",
        "    training_accuracy.append(clf.score(X_train, y_train))\n",
        "    # 일반화 정확도 저장\n",
        "    test_accuracy.append(clf.score(X_test, y_test))\n",
        "\n",
        "#각 데이터셋의 정확도를 한눈에 파악이 쉽도록 그래프로 출력해봅니다.\n",
        "plt.plot(neighbors_settings, training_accuracy, label=\"train dataset accuracy\")\n",
        "plt.plot(neighbors_settings, test_accuracy, label=\"test dataset accuracy\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.xlabel(\"n_neighbors\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# 이웃의 수가 늘어나면 모델은 단순해지고(덜 까다로워지므로) 훈련 데이터의 정확도는 줄어드는 양상을 보입니다.\n",
        "# 이 경우 정확도가 가장 좋을 때는 중간 정도인 6개를 사용한 경우로, 92.98% 입니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxarQxDSKN8z"
      },
      "source": [
        "이제 정규화(Normalisation) 작업을 추가하여 재도전 해보겠습니다. <br>\n",
        "프로세스나 정확률에 차이가 있는지도 함께 지켜봐주세여.\n",
        "\n",
        "# 0. 본격 예제 들어가기 전에 메서드나 모델에 대한 간단 설명입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWedW9zINN5_"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#이제 KNeighborsClassifier 모델을 생성해야 하는데, 이 때 n_neighbors로 k를 정해줘야 합니다. \n",
        "#(그리고 x 데이터를 분류를 할 때 k개의 이웃 중 \"거리가 가까운 이웃\" 의 영향을 더 많이 받도록 가중치를 설정하려면 \n",
        "#weights = \"distance\"를 지정해줄 수 있는데 여기서는 일단 생략하기로 합니다.)\n",
        "classifier = KNeighborsClassifier(n_neighbors = 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJbTHNvmM44I",
        "outputId": "ab83b094-f837-46cf-d1a3-9c77763258b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "# 그 다음 데이터를 .fit() 시켜줍니다. \n",
        "# x 데이터는 여러 개의 차원으로 이루어진 배열(점들의 집합)이 될 거고, \n",
        "# y 데이터는 레이블(각 점들의 분류 결과)가 됩니다. \n",
        "# 이 예제에서는 0 혹은 1로 분류될것입니다.\n",
        "training_points = [\n",
        "  [0.5, 0.2, 0.1],\n",
        "  [0.9, 0.7, 0.3],\n",
        "  [0.4, 0.5, 0.7]\n",
        "]\n",
        "training_labels = [0, 1, 1]\n",
        "classifier.fit(training_points, training_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9jTEyU_NQRy"
      },
      "source": [
        "#이제 만약 새로운 값들을 분류하고 싶다면 .predict()를 사용하면 됩니다.\n",
        "unknown_points = [\n",
        "  [0.2, 0.1, 0.7],\n",
        "  [0.4, 0.7, 0.6],\n",
        "  [0.5, 0.8, 0.1]\n",
        "]\n",
        "guesses = classifier.predict(unknown_points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtVJylO9N1Ds"
      },
      "source": [
        "#1. 데이터, 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w5RwqKmNach"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer_data = load_breast_cancer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLBQ0FPDN7Y4",
        "outputId": "136c25ae-d85b-4f2f-c12d-7058ab17a676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# 데이터 확인을 pandas의 데이터 프레임으로 바꿔서 해보겠습니다.\n",
        "# .data를 찍어주면 데이터, .target을 찍어주면 레이블을 돌려줍니다.\n",
        "\n",
        "import pandas as pd\n",
        "df_data = pd.DataFrame(breast_cancer_data.data)\n",
        "df_labels = pd.DataFrame(breast_cancer_data.target)\n",
        "\n",
        "# 데이터를 찍어보면 0과 1로 분류되어있는것을 확인해 볼 수 있습니다.\n",
        "df_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "..  ..\n",
              "564  0\n",
              "565  0\n",
              "566  0\n",
              "567  0\n",
              "568  1\n",
              "\n",
              "[569 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBSr-ZdyORI9",
        "outputId": "71be0ca2-3950-46af-83d3-890c33b092df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 그 0과 1 이 무엇을 의미하는 걸까요? 타켓 네임을 출력해보면\n",
        "#아래와 같이 'malignant' =악성 'benign' =양성 인 것을 알 수 있습니다.\n",
        "print(breast_cancer_data.target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['malignant' 'benign']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxVDdpLGOknU",
        "outputId": "991396ba-d431-4aba-af00-26588440a0bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# 그러나 df.data에서 문제를 발견하게 됩니다.\n",
        "\n",
        "df_data.head()\n",
        "\n",
        "# 이름이나 칼럼같은것도 없이 그냥 30개 항목에 대한 값만 쭉 들어 있습니다.\n",
        "# 그런데 값이 어떤 건 엄청 큰 거 같고(3번칼럼의 4번 로우는 1297.0로 매우 큼) 어떤 건 1이 채 안되는 것 같습니다..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0      1       2       3   ...      26      27      28       29\n",
              "0  17.99  10.38  122.80  1001.0  ...  0.7119  0.2654  0.4601  0.11890\n",
              "1  20.57  17.77  132.90  1326.0  ...  0.2416  0.1860  0.2750  0.08902\n",
              "2  19.69  21.25  130.00  1203.0  ...  0.4504  0.2430  0.3613  0.08758\n",
              "3  11.42  20.38   77.58   386.1  ...  0.6869  0.2575  0.6638  0.17300\n",
              "4  20.29  14.34  135.10  1297.0  ...  0.4000  0.1625  0.2364  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl6X5IuxOI0M",
        "outputId": "c661ed03-12c3-4c6a-b4ff-302f193d6495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "# 각 항목별로 최대/최소값을 비롯한 기초 통계량을 확인하기 위해 .describe()를 찍어봅니다.\n",
        "\n",
        "df_data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0           1           2   ...          27          28          29\n",
              "count  569.000000  569.000000  569.000000  ...  569.000000  569.000000  569.000000\n",
              "mean    14.127292   19.289649   91.969033  ...    0.114606    0.290076    0.083946\n",
              "std      3.524049    4.301036   24.298981  ...    0.065732    0.061867    0.018061\n",
              "min      6.981000    9.710000   43.790000  ...    0.000000    0.156500    0.055040\n",
              "25%     11.700000   16.170000   75.170000  ...    0.064930    0.250400    0.071460\n",
              "50%     13.370000   18.840000   86.240000  ...    0.099930    0.282200    0.080040\n",
              "75%     15.780000   21.800000  104.100000  ...    0.161400    0.317900    0.092080\n",
              "max     28.110000   39.280000  188.500000  ...    0.291000    0.663800    0.207500\n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hMbT4vuyn1F"
      },
      "source": [
        "역시. 최댓값 최솟값의 편차가 몹시 심합니다.\n",
        "<br>항목마다 스케일이 너무나 다른데 그걸 무시한 채 동일한 정도로 학습에 반영하면 안 될 것 같습니다. \n",
        "<br>이때 사용하는 것이 정규화(Normalisation)라고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvWY9pBPPfdT"
      },
      "source": [
        "# 본 예제에서는 최소-최대 정규화 함수를 작성한 후\n",
        "\n",
        "def min_max_normalize(lst):\n",
        "    normalized = []\n",
        "    \n",
        "    for value in lst:\n",
        "        normalized_num = (value - min(lst)) / (max(lst) - min(lst))\n",
        "        normalized.append(normalized_num)\n",
        "    \n",
        "    return normalized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzwm3aeFPlK0",
        "outputId": "2d795cb4-07b9-49c4-c34c-a60498e3dcf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "# df_data에 적용해 봅니다.\n",
        "for x in range(len(df_data.columns)):\n",
        "    df_data[x] = min_max_normalize(df_data[x])\n",
        "df_data.describe()\n",
        "# 모든 항목이 최소값은 0, 최대값은 1로 변환된 걸 확인할 수 있습니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.338222</td>\n",
              "      <td>0.323965</td>\n",
              "      <td>0.332935</td>\n",
              "      <td>0.216920</td>\n",
              "      <td>0.394785</td>\n",
              "      <td>0.260601</td>\n",
              "      <td>0.208058</td>\n",
              "      <td>0.243137</td>\n",
              "      <td>0.379605</td>\n",
              "      <td>0.270379</td>\n",
              "      <td>0.106345</td>\n",
              "      <td>0.189324</td>\n",
              "      <td>0.099376</td>\n",
              "      <td>0.062636</td>\n",
              "      <td>0.181119</td>\n",
              "      <td>0.174439</td>\n",
              "      <td>0.080540</td>\n",
              "      <td>0.223454</td>\n",
              "      <td>0.178143</td>\n",
              "      <td>0.100193</td>\n",
              "      <td>0.296663</td>\n",
              "      <td>0.363998</td>\n",
              "      <td>0.283138</td>\n",
              "      <td>0.170906</td>\n",
              "      <td>0.404138</td>\n",
              "      <td>0.220212</td>\n",
              "      <td>0.217403</td>\n",
              "      <td>0.393836</td>\n",
              "      <td>0.263307</td>\n",
              "      <td>0.189596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.166787</td>\n",
              "      <td>0.145453</td>\n",
              "      <td>0.167915</td>\n",
              "      <td>0.149274</td>\n",
              "      <td>0.126967</td>\n",
              "      <td>0.161992</td>\n",
              "      <td>0.186785</td>\n",
              "      <td>0.192857</td>\n",
              "      <td>0.138456</td>\n",
              "      <td>0.148702</td>\n",
              "      <td>0.100421</td>\n",
              "      <td>0.121917</td>\n",
              "      <td>0.095267</td>\n",
              "      <td>0.084967</td>\n",
              "      <td>0.102067</td>\n",
              "      <td>0.134498</td>\n",
              "      <td>0.076227</td>\n",
              "      <td>0.116884</td>\n",
              "      <td>0.116316</td>\n",
              "      <td>0.091417</td>\n",
              "      <td>0.171940</td>\n",
              "      <td>0.163813</td>\n",
              "      <td>0.167352</td>\n",
              "      <td>0.139932</td>\n",
              "      <td>0.150779</td>\n",
              "      <td>0.152649</td>\n",
              "      <td>0.166633</td>\n",
              "      <td>0.225884</td>\n",
              "      <td>0.121954</td>\n",
              "      <td>0.118466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.223342</td>\n",
              "      <td>0.218465</td>\n",
              "      <td>0.216847</td>\n",
              "      <td>0.117413</td>\n",
              "      <td>0.304595</td>\n",
              "      <td>0.139685</td>\n",
              "      <td>0.069260</td>\n",
              "      <td>0.100944</td>\n",
              "      <td>0.282323</td>\n",
              "      <td>0.163016</td>\n",
              "      <td>0.043781</td>\n",
              "      <td>0.104690</td>\n",
              "      <td>0.040004</td>\n",
              "      <td>0.020635</td>\n",
              "      <td>0.117483</td>\n",
              "      <td>0.081323</td>\n",
              "      <td>0.038106</td>\n",
              "      <td>0.144686</td>\n",
              "      <td>0.102409</td>\n",
              "      <td>0.046750</td>\n",
              "      <td>0.180719</td>\n",
              "      <td>0.241471</td>\n",
              "      <td>0.167837</td>\n",
              "      <td>0.081130</td>\n",
              "      <td>0.300007</td>\n",
              "      <td>0.116337</td>\n",
              "      <td>0.091454</td>\n",
              "      <td>0.223127</td>\n",
              "      <td>0.185098</td>\n",
              "      <td>0.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.302381</td>\n",
              "      <td>0.308759</td>\n",
              "      <td>0.293345</td>\n",
              "      <td>0.172895</td>\n",
              "      <td>0.390358</td>\n",
              "      <td>0.224679</td>\n",
              "      <td>0.144189</td>\n",
              "      <td>0.166501</td>\n",
              "      <td>0.369697</td>\n",
              "      <td>0.243892</td>\n",
              "      <td>0.077023</td>\n",
              "      <td>0.165267</td>\n",
              "      <td>0.072092</td>\n",
              "      <td>0.033112</td>\n",
              "      <td>0.158650</td>\n",
              "      <td>0.136675</td>\n",
              "      <td>0.065379</td>\n",
              "      <td>0.207047</td>\n",
              "      <td>0.152643</td>\n",
              "      <td>0.079191</td>\n",
              "      <td>0.250445</td>\n",
              "      <td>0.356876</td>\n",
              "      <td>0.235320</td>\n",
              "      <td>0.123206</td>\n",
              "      <td>0.397081</td>\n",
              "      <td>0.179110</td>\n",
              "      <td>0.181070</td>\n",
              "      <td>0.343402</td>\n",
              "      <td>0.247782</td>\n",
              "      <td>0.163977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.416442</td>\n",
              "      <td>0.408860</td>\n",
              "      <td>0.416765</td>\n",
              "      <td>0.271135</td>\n",
              "      <td>0.475490</td>\n",
              "      <td>0.340531</td>\n",
              "      <td>0.306232</td>\n",
              "      <td>0.367793</td>\n",
              "      <td>0.453030</td>\n",
              "      <td>0.340354</td>\n",
              "      <td>0.133044</td>\n",
              "      <td>0.246155</td>\n",
              "      <td>0.122509</td>\n",
              "      <td>0.071700</td>\n",
              "      <td>0.218683</td>\n",
              "      <td>0.226800</td>\n",
              "      <td>0.106187</td>\n",
              "      <td>0.278651</td>\n",
              "      <td>0.219480</td>\n",
              "      <td>0.126556</td>\n",
              "      <td>0.386339</td>\n",
              "      <td>0.471748</td>\n",
              "      <td>0.373475</td>\n",
              "      <td>0.220901</td>\n",
              "      <td>0.494156</td>\n",
              "      <td>0.302520</td>\n",
              "      <td>0.305831</td>\n",
              "      <td>0.554639</td>\n",
              "      <td>0.318155</td>\n",
              "      <td>0.242949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0           1           2   ...          27          28          29\n",
              "count  569.000000  569.000000  569.000000  ...  569.000000  569.000000  569.000000\n",
              "mean     0.338222    0.323965    0.332935  ...    0.393836    0.263307    0.189596\n",
              "std      0.166787    0.145453    0.167915  ...    0.225884    0.121954    0.118466\n",
              "min      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "25%      0.223342    0.218465    0.216847  ...    0.223127    0.185098    0.107700\n",
              "50%      0.302381    0.308759    0.293345  ...    0.343402    0.247782    0.163977\n",
              "75%      0.416442    0.408860    0.416765  ...    0.554639    0.318155    0.242949\n",
              "max      1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXkpRNZ6QYfe"
      },
      "source": [
        "# 2 데이터 세트 분리하기 (Training & Validation)\n",
        "- 가지고 있는 데이터를 모두 사용해서 분류 모델을 만들 수도 있지만, <br>\n",
        "지금은 실제로 생성한 분류 모델의 성능을 테스트를 해봐야 하니까 <br>\n",
        "학습(training) 세트와 검증(validation) 세트를 분리해보겠습니다. <br>\n",
        "- 모든 데이터에는 분류된 레이블(target)이 있으니, <br>\n",
        "검증 데이터를 예측 모델에 넣어서 실제 그 레이블(정답)을 잘 맞추는지 보기 위함입니다.<br>\n",
        "- 데이터 세트 분리는 사이킷런의 train_test_split을 통해 손쉽게 할 수 있습니다.\n",
        "- 데이터 세트를 나누는 비율을 지정할 수도 있는데, 일반적으로 0.75:0.25, 즉 3:1이라고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVklYLvJPLB9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "training_data, validation_data , training_labels, validation_labels = train_test_split(df_data, df_labels, test_size = 0.2, random_state = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMSyzFXTRBm7",
        "outputId": "abd9e0bc-27af-49fb-9d95-7b6e9bb5d5cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# 나눠진 데이터 개수를 찍어봅시다.\n",
        "print(len(training_data))\n",
        "print(len(validation_data))\n",
        "print(len(training_labels))\n",
        "print(len(validation_labels))\n",
        "# 455:144 대략 8:2로 분리된 걸 확인할 수 있습니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "455\n",
            "114\n",
            "455\n",
            "114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygiIcl89SZ2W"
      },
      "source": [
        "# 3 모델 생성하기\n",
        "- 이제 학습 데이터를 가지고 모델을 생성할 것입니다. k=3으로 지정해봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCjnS3l2STyO",
        "outputId": "b42e57e8-3fdd-45c8-99eb-eb20ca898481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 3)\n",
        "\n",
        "# 이제 위에서 나눠놓은 학습 데이터 세트(training_data, training_labels)로 학습시켜보겠습니다.\n",
        "classifier.fit(training_data, training_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRuj1-dbzBAC"
      },
      "source": [
        "# 4 모델의 정확도(Accuracy) 평가하기\n",
        "\n",
        "- 위에서 데이터 세트를 나눠놨기 때문에 학습시킨 모델을 바로 테스트 할 수 있습니다.\n",
        "- 이때 당연히 검증 세트의 데이터와 레이블을 넣어줘야 합니다.\n",
        "- KNeighborsClassifier에서는 .score()를 쓰면 모델의 정확도를 바로 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvvVWaRtSdNe",
        "outputId": "155c6735-b9f6-4198-ac1f-f4d26fb7309f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(classifier.score(validation_data, validation_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9649122807017544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3NBEHgF2xzl"
      },
      "source": [
        "k = 3 일때 정확도가 96.49%로 꽤 높게 측정되었습니다. <br>\n",
        "이제 k 값이 정확도에 미치는 영향이 궁금해집니다. <br>\n",
        "따라서 k = 1~100 로 적용하여 테스트 해보기로 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4uyT-waSdTd",
        "outputId": "1bf41a0f-8d28-44f1-8ecb-ac67fa41bf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "k_list = range(1,101)\n",
        "accuracies = []\n",
        "for k in k_list:\n",
        "  classifier = KNeighborsClassifier(n_neighbors = k)\n",
        "  classifier.fit(training_data, training_labels)\n",
        "  accuracies.append(classifier.score(validation_data, validation_labels))\n",
        "plt.plot(k_list, accuracies)\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.title(\"Breast Cancer Classifier Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8P_L7kG3JGj"
      },
      "source": [
        "- 먼저 노트, underfitting 은 모델이 학습 오류를 줄이지 못하는 상황을 의미하고, 오버피팅(overfitting)은 모델 학습 오류가 테스트 데이터의 오류보다 훨씬 작은 경우를 의미합니다.\n",
        "- k가 커질수록 underfitting이 생겨서 정확도가 떨어지는 걸 확인할 수 있는데, 모델이 대충 대충 집어서 확인하게 되기 때문에 벌어지는 현상입니다.\n",
        "- 어쨌든 적절한 k값을 찾아 분류 모델을 생성해주면 되겠습니다. 또한 이후에 .predict()로 레이블을 예측하는 것도 가능하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXIMV1T0GbQ9"
      },
      "source": [
        "# 이제 Decision Tree 가 무엇인지 궁금해졌다고 가정하고 <br> 저희가 가진 데이터에 적용해 보기로 합니다.\n",
        "\n",
        "- 의사결정 트리는 특정 항목에 대한 측정값을 목표가 되는 값에 매핑시켜주는 분석기법으로, 의사결정과정의 규칙을 이용해서 Tree 구조로 만든 분류모델 이라고 합니다.\n",
        "- 제가 보기엔 스무고개랑 비슷한 매커니즘입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4OIBxBs3D4D"
      },
      "source": [
        "# 관련 라이브러리와 데이터 로드\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pydot #의사결정트리를 쉽게 시각화 할때 쓰는 아이라고 합니다. 궁금하니 사용해보기로 합니다.\n",
        "\n",
        "\n",
        "# KNN예제를 따로 실행시키지 않아도 되도록 샘플 데이터 다시 로드.\n",
        "from sklearn.datasets import load_breast_cancer \n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# 훈련, 테스트 데이터 셔플하기\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    cancer.data, cancer.target, stratify =  cancer.target, random_state = 42)\n",
        "# 위에서 stratify ... 라고 하는 부분을 찾아보니 지정한 데이터의 비율을 유지해주는 아이라고 합니다.\n",
        "# 만약 라벨셋인 y가 25%의  0과 75%의 1로 이루어진 바이너리 데이터셋일때\n",
        "# stratify = y 로 설정하면 스플릿 된 데이터셋들도 0과 1이 각각 25%, 75%로\n",
        "# 유지된 채 분할된다고 합니다. 유용하겠네요."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uebv6njDH7Zr",
        "outputId": "b34ca764-ec8a-4446-8c1d-b5bfe3da1ffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Decision Tree 선언하기\n",
        "dTreeAll = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "#훈련 (모든 리프 노드 사용해서 학습시키기)\n",
        "dTreeAll.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY43AW6_JZHc",
        "outputId": "3375dbcc-c2c5-4b7e-ea82-380a5ecc5c97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#위 결과에 대해 모델 평가해보기\n",
        "print(\"Train Set Score1 : {:.2f}\".format(dTreeAll.score(X_train, y_train)))\n",
        "print(\"Test Set Score1 : {}:.2f\".format(dTreeAll.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Score1 : 1.00\n",
            "Test Set Score1 : 0.9370629370629371:.2f\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF8GBetwUOR8"
      },
      "source": [
        "- 트레인 셋의 점수가 1.00 인 당혹스런 현상에 대해서는 선생님께서 설명해주실 것입니다.\n",
        "- 제가 참조한 예제에서 작가분께서는 깊이(Depth) 가 커지면 새로운 데이터를 적용하기가 곤란하고, 가장 중요한 단점인 예측 오차의 수치가 비약적으로 높아지는 경우가 있다고 합니다.\n",
        "\n",
        "- 이럴 경우! 데이터 특성 파악하는 과정을 거친 후에 가지치기(pruning)를 활용하여 이 깊이를 조절해줄 필요성이 있다고 합니다.\n",
        "- 여기서 가지치기의 감도 조절 또한 가능한데, reduced error pruning 또는 rule post pruning 등의 기법을 적용해 볼 수도 있다고 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5No054a0J0d3",
        "outputId": "ed5ead0a-dfe2-4014-b99b-667ee1d5bc08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 이제 의사결정 트리를 깊이를 제한하여 다시 선언해 보겠습니다.\n",
        "dTreeLimit = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
        "\n",
        "# 그리고 다시 훈련.\n",
        "dTreeLimit.fit(X_train, y_train)\n",
        "\n",
        "# 점수를 출력해봅니다.\n",
        "print(\"Train Set Score2 : {:.2f}\".format(dTreeLimit.score(X_train, y_train)))\n",
        "print(\"Test Set Score2 : {:.2f}\".format(dTreeLimit.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Score2 : 0.98\n",
            "Test Set Score2 : 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6-1KfCPNZM3"
      },
      "source": [
        "# graphviz 의사결정트리 시각화 작업을 시작해봅니다.\n",
        "export_graphviz(dTreeLimit, out_file=\"decisionTree1.dot\", class_names=[\"malignant\",\"benign\"],\n",
        "                feature_names=cancer.feature_names, impurity=False, filled=True)\n",
        "\n",
        "# 중요한 Encoding\n",
        "(graph,) = pydot.graph_from_dot_file('decisionTree1.dot', encoding='utf8')\n",
        "\n",
        "#Dot 파일을 Png 이미지로 저장\n",
        "graph.write_png('decisionTree1.png')\n",
        "\n",
        "# 뭔가 Files 에 저장이 되었습니다! 함께 확인해볼까요\n",
        "# 해독하는 법은 선생님께서 설명해주실거죠? (찡긋)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEzCg9FhPczd"
      },
      "source": [
        "# 이제 Perceptron을 이용한 예제입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_GF-D1MQDFN"
      },
      "source": [
        "# 도마와 칼, 재료를 준비해줍니다.\n",
        "# 종종 보일 MLP는 Multi-Layer Perceptron이라고도 하는 다층 퍼셉트론의 약자입니다.\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64oO4UPKQygy"
      },
      "source": [
        "cancer = load_breast_cancer()\n",
        "# x축에 input 데이터 나열하고    \n",
        "X=cancer.data  \n",
        " # y축에 타겟 데이터 나열해 줍니다.        \n",
        "y=cancer.target             \n",
        "# 훈련 데이터와 테스트 데이터로 쪼개줍니다. test_size=0.2이므로 8:2 비율입니다.\n",
        "X_train_all, X_test, y_train_all, y_test = \\\n",
        "  train_test_split(X,y,stratify=y,test_size=0.2,random_state=42)  \n",
        "# 훈련 데이터와 검증 데이터 분류. val 이라고 하는 낯선아이가 등장했습니다. \n",
        "# 새로운 아이인줄 알았더니 모델 평가를 위해 얘를 사용할 모양입니다. \n",
        "# 그렇다면 validation의 약자인것 같습니다.\n",
        "# 역시 8:2 비율입니다.\n",
        "X_train, X_val, y_train, y_val = \\\n",
        "  train_test_split(X_train_all,y_train_all,stratify=y_train_all, \\\n",
        "                   test_size=0.2,random_state=42)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inRXvloCSQFI"
      },
      "source": [
        "# scaler 라는 객체를 만들어서 사용할 것인데,\n",
        "# StandardScaler 는 평균과 표준편차 사용해서 데이터 특성의 스케일을 맞춰줍니다.\n",
        "scaler = StandardScaler()   \n",
        "scaler.fit(X_train)\n",
        "\n",
        "# 위의 scaler로 데이터를 표준화 전처리하는 과정입니다. \n",
        "# 구분짓기 위해 이름 뒤에 _scaled 표현도 넣어줍니다.\n",
        "X_train_scaled = scaler.transform(X_train)  \n",
        "X_val_scaled = scaler.transform(X_val)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADqZ9ChKWHSx"
      },
      "source": [
        "# 이제 퍼셉트론 분류기를 사용하려나봅니다. 꺄륵.\n",
        "# 길고 무서워보이는 이름 대신에 mlp라는 별명을 주어 사용하겠습니다.\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='logistic', \\\n",
        "                    solver='sgd', alpha=0.01, batch_size=32, \\\n",
        "                    learning_rate_init=0.1, max_iter=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnigO6__WXAW"
      },
      "source": [
        "- 활성화 함수로 로지스틱을 사용하였는데, 어쩐지 퍼셉트론 강의를 시작하기 전에 로지스틱 회귀 공부를 필수로 해야한다고 하더라구요. 그 이유를 아주 대충 정리해 보았습니다.\n",
        "- 먼저 퍼셉트론의 애칭이 인공 신경망이던데 얘가 모티브로 한 실제 뉴런의 동작 모습을 정리해보면 이해가 빠르겠습니다.\n",
        "- 실제 뉴런이 크게 둘로 나눈다면 Dendrite(수상돌기: 입력층, 다중일 수 있음) 과 Axon(축삭돌기: 출력층, only 하나) 이렇게 나눌 수 있습니다.\n",
        "- 실제 뉴런에서는 세포에 입력된 다수의 입력이 하나로 합산되어 하나인 axon 으로 출력 되는데, 그 값이 각각 입/출력 이라 불리는 1(on 상태), 0(off 상태) 만 가능합니다.\n",
        "- 이 입/출력\u001d을 함수로 나타낸 방식이 로지스틱 회귀와 매우 비슷하다는 것까지만 조사를 해 보았습니다.\n",
        "- 로지스틱스가 단극 시그모이드 함수라면 양극성 시그모이드도 존재하겠습니다.(쌍곡탄젠트: -1 과 1 사이의 값을 가짐.) 흥미롭네요. (하하)\n",
        "- solver 는 전에 정민님 예제에서 adam 으로 쓰였던걸 본 기억이 있는것 같습니다.\n",
        "- 여기서 해결하지 못한 질문이 하나 생겼습니다. 알아보니 사이킷런에 구현되어있는 로지스틱의 기본 solver 값이 'lbfgs'라고 하던데...\n",
        "- 저희 예제가 sgd를 사용한 특별한 의미가 있을까요? 둘 차이점이 분명히 있는것같은데 누구보다 빠르게 이해를 포기했습니다. ^^"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zxUR4JKM_gi",
        "outputId": "5a97f4c7-fdf4-4e76-83fd-f04aff714ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 이제 훈련합니다.\n",
        "mlp.fit(X_train_scaled, y_train)   \n",
        " #.score() 사용하여 정확도를 평가해봅니다.\n",
        "mlp.score(X_val_scaled, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.978021978021978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}